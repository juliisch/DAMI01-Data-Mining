{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ =  'Julia Schmid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAMI01 Data Mining\n",
    "## Erstellung eines Data Mining Projektes unter der Berücksichtigung des CRISP-DM Ansatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auskommentieren für die Installation der benötigen Pakete?\n",
    "#pip install numpy pandas matplotlib math seaborn os\n",
    "# #X!X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE_DIR = os.path.dirname(os.path.abspath(\"\"))\n",
    "#INPUT_CSV_FILE = os.path.join(BASE_DIR, \"03_Clustering_Marketing.csv\")\n",
    "#print(\"Local path to the dataset: %s\" % INPUT_CSV_FILE)\n",
    "#df = pd.read_csv(INPUT_CSV_FILE, sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einstellungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from kneed import KneeLocator\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Spalten eines Datensatzes anzeigen\n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten einlesen\n",
    "Datenquelle: Ullah, Z. (2024). Kaggle. Angerufen am 14. Februar 2024 von https:// www.kaggle.com/ datasets/ zabihullah18/ students-\n",
    "social-network-profile-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"03_Clustering_Marketing.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten Verstehen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der ersten 5 Zeilen\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Anzahl der Zeilen und Spalten\n",
    "print(f'Anzahl Zeilen: {df.shape[0]}')\n",
    "print(f'Anzahl Spalten: {df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Datensatz-Info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Statistischenkennzahlen der numerischen Variablen\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestimmung der Numerische Variablen \n",
    "numerical_var = [col for col in df if df[col].dtype != 'object']\n",
    "print(numerical_var)\n",
    "\n",
    "# Bestimmung der Kategorische Variablen\n",
    "categorical_var = [col for col in df if df[col].dtype == 'object']\n",
    "print(categorical_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Kategorische Variablen plotten \n",
    "# for i in categorical_var:\n",
    "#     plt.figure(figsize=(5, 3)) \n",
    "#     df[i].value_counts().plot(kind='bar')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Numerische Variablen plotten \n",
    "# for i in numerical_var:\n",
    "#     plt.figure(figsize=(5, 3))\n",
    "#     sns.histplot(data=df, x=i)  \n",
    "#     plt.xlabel(i)  \n",
    "#     plt.ylabel('Anzahl')        \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten aufbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NaN-Werte**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe des Namens der Variablen mit NaN-Werte und die Anzahl der Einträge mit NaN-Werten\n",
    "count_nan = df.isna().sum()\n",
    "count_nan[count_nan > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fehlende Werte beim der Variable gender werden durch \"U\" (Unknonw) gefüllt\n",
    "print(df['gender'].unique())\n",
    "df['gender']= df['gender'].fillna('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fehlende Werte bei der Variable age werden mit dem Durchschnittsalter vom dazugehörigen Abschlussjahr gefüllt\n",
    "print(df['age'].unique())\n",
    "\n",
    "df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "df['age'] = df['age'].apply(lambda x: math.floor(x) if pd.notna(x) else x)\n",
    "df['age'] = df.groupby('gradyear')['age'].transform(lambda x: x.fillna(x.mean()))\n",
    "df['age'] = df['age'].astype(int)\n",
    "\n",
    "df['age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Duplikate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bearbeitung der Ausreißer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter ändern: Ausreißer werden mit der IQR-Methode bearbeitet\n",
    "q1 = df['age'].quantile(0.25)\n",
    "q3 = df['age'].quantile(0.75)\n",
    "iqr = q3-q1\n",
    "df = df[(df['age'] > (q1 - 1.5*iqr)) & (df['age'] < (q3 + 1.5*iqr))]\n",
    "df['age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datentransformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'gender' in einen numerischen Datentyp ändern\n",
    "# Female (F) = 1, Male (M) = 2, Unknonwn (U) = 2\n",
    "df['gender'] = df['gender'].replace({'F': 1, 'M': 2, 'U': 3}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speicherung der Namen der Variablen mit der Häufigekits \n",
    "mentions = df.columns[4:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Skalierung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = df.copy()\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_scaled[df.columns] = scaler.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bestimmung der Clusteranzahl**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ellbogenmethode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "\n",
    "for i in range(1, 41):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(df_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "knee_locator = KneeLocator(range(1, 41), wcss, curve=\"convex\", direction=\"decreasing\")\n",
    "best_n_clusters = knee_locator.knee\n",
    "    \n",
    "# Plot der WCSS für verschiedene Clusteranzahlen\n",
    "plt.plot(range(1, 41), wcss)\n",
    "plt.title('Ellbogenmethode')\n",
    "plt.xlabel('Anzahl an Clustern')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Die optimale Clusteranzahl ist {best_n_clusters}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Silhoutten-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silScores = []\n",
    "\n",
    "for i in range(2, 40):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(df_scaled)\n",
    "    labels = kmeans.labels_\n",
    "    score = silhouette_score(df_scaled, labels)\n",
    "    silScores.append(score)\n",
    "\n",
    "# Plot der Silhouetten Score für verschiedene Clusteranzahlen\n",
    "plt.plot(range(2, 40), silScores)\n",
    "plt.title('Silhouetten Score')\n",
    "plt.xlabel('Anzahl an Clustern')\n",
    "plt.ylabel('Silhouetten Score')\n",
    "plt.show()\n",
    "\n",
    "# Bestimmung der optiomalen Clusteranzahl (Maximaler Silhouetten Score)\n",
    "silScores_neu = silScores[1:] # Ersten Wert ausschließen\n",
    "best_n_clusters = silScores[1:].index(max(silScores[1:])) + 2 # Clusteranzahl beginnt bei 2\n",
    "print(f\"Die optimale Clusteranzahlr ist {best_n_clusters}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dbIndex = pd.DataFrame(columns=[\"clusterName\", \"db_index\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans_Modell(numbCluster, randomState, dfScaled, dfUnscaled, nameVar, df_dbIndex):\n",
    "    kmeans = KMeans(n_clusters = numbCluster,  random_state = randomState)\n",
    "    kmeans = kmeans.fit(dfScaled)\n",
    "    y_pred = kmeans.predict(dfScaled)\n",
    "    dfUnscaled[nameVar] = kmeans.labels_\n",
    "    temp = kmeans.labels_\n",
    "    db_index_value = davies_bouldin_score(dfScaled, temp)\n",
    "    df_dbIndex.loc[len(df_dbIndex)] = [nameVar, db_index_value]\n",
    "    return dfUnscaled, df_dbIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_dbIndex =  KMeans_Modell(6, 42, df_scaled, df, 'cluster_kmeans (k=6)', df_dbIndex)\n",
    "df, df_dbIndex =  KMeans_Modell(7, 42, df_scaled, df, 'cluster_kmeans (k=7)', df_dbIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Hierarchisches Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def hierarchy_Modell(numbCluster, nameVar, dfScaled, dfUnscaled, df_dbIndex):\n",
    "    hierarch = linkage(dfScaled, method='complete')\n",
    "    hierarch_label = fcluster(hierarch, numbCluster, criterion='maxclust')\n",
    "    dfUnscaled[nameVar] = hierarch_label\n",
    "    db_index_value = davies_bouldin_score(dfScaled, hierarch_label)\n",
    "    df_dbIndex.loc[len(df_dbIndex)] = [nameVar, db_index_value]\n",
    "    return dfUnscaled, df_dbIndex \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" df, df_dbIndex = hierarchy_Modell(6, 'cluster_hierarch', df_scaled, df, df_dbIndex) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestimmung der optimalen Parameter eps und MinPts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinPts≥D+1 oder MinPts=2×D\n",
    "# eps = ellbogen Methode (am stärksten zunimmt) --> k = MinPts−1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension des Datensatzes\n",
    "D = df_scaled.shape[1]\n",
    "print(f\"Die Dimension des Datensatz ist {D}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minPts_var = D+1 \n",
    "minPts_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 41 - 1\n",
    "neighbors = NearestNeighbors(n_neighbors=k)\n",
    "neighbors_fit = neighbors.fit(df_scaled)\n",
    "distances, indices = neighbors_fit.kneighbors(df_scaled)\n",
    "distances = np.sort(distances, axis=0)\n",
    "\n",
    "distances = distances[:,k-1] # Letzte Distanz betrachten\n",
    "plt.figure(figsize = (5,3))\n",
    "plt.plot(distances)\n",
    "plt.show()\n",
    "\n",
    "knee_locator = KneeLocator(range(1, len(distances) + 1), distances, curve=\"convex\", direction=\"increasing\")\n",
    "optimal_k = knee_locator.knee\n",
    "epsilon_var = distances[optimal_k - 1]\n",
    "print(epsilon_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.45, min_samples=(2*D))\n",
    "dbscan.fit(df_scaled)\n",
    "\n",
    "df['cluster_dbscans'] = dbscan.labels_\n",
    "\n",
    "temp = dbscan.labels_\n",
    "db_index_value = davies_bouldin_score(df_scaled, temp)\n",
    "df_dbIndex.loc[len(df_dbIndex)] = ['cluster_dbscans', db_index_value] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=epsilon_var, min_samples=(minPts_var))\n",
    "dbscan.fit(df_scaled)\n",
    "\n",
    "df['cluster_dbscans'] = dbscan.labels_\n",
    "\n",
    "temp = dbscan.labels_\n",
    "db_index_value = davies_bouldin_score(df_scaled, temp)\n",
    "df_dbIndex.loc[len(df_dbIndex)] = ['cluster_dbscans', db_index_value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Fuzzy C-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skfuzzy as fuzz\n",
    "\n",
    "n_clusters = 6\n",
    "\n",
    "# Fuzzy C-Means Clustering\n",
    "cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "    df_scaled.T, c=n_clusters, m=2.0, error=0.005, maxiter=1000, init=None        \n",
    ")\n",
    "df[\"cluster_fuzzy (k=6)\"] = np.argmax(u, axis=0)\n",
    "\n",
    "temp = np.argmax(u, axis=0)\n",
    "db_index_value = davies_bouldin_score(df_scaled, temp)\n",
    "df_dbIndex.loc[len(df_dbIndex)] = ['cluster_fuzzy (k=6)', db_index_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skfuzzy as fuzz\n",
    "\n",
    "n_clusters = 7\n",
    "\n",
    "# Fuzzy C-Means Clustering\n",
    "cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "    df_scaled.T, c=n_clusters, m=2.0, error=0.005, maxiter=1000, init=None        \n",
    ")\n",
    "df[\"cluster_fuzzy (k=7)\"] = np.argmax(u, axis=0)\n",
    "\n",
    "temp = np.argmax(u, axis=0)\n",
    "db_index_value = davies_bouldin_score(df_scaled, temp)\n",
    "df_dbIndex.loc[len(df_dbIndex)] = ['cluster_fuzzy (k=7)', db_index_value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsCluster = ['cluster_kmeans (k=6)','cluster_kmeans (k=7)', 'cluster_dbscans','cluster_fuzzy (k=6)', 'cluster_fuzzy (k=7)']\n",
    "\n",
    "value_counts_dict = {column: df[column].value_counts() for column in columnsCluster}\n",
    "\n",
    "df_result = pd.DataFrame(value_counts_dict).fillna(0).astype(int)\n",
    "df_result.columns = [f'{col}' for col in df_result.columns]\n",
    "df_result.reset_index(inplace=True)\n",
    "df_result.rename(columns={'index': 'Cluster'}, inplace=True)\n",
    "df_result = df_result.sort_values(by='Cluster').reset_index(drop=True)\n",
    "df_result = df_result.set_index('Cluster').T\n",
    "\n",
    "df_result.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "plt.legend(title=\"Cluster\", loc='upper left', bbox_to_anchor=(1.05, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "# Funktion: Bestimmung der Top 10 Themen pro Cluster\n",
    "def top10Mention(df, clusterVar):\n",
    "    cluster_analysis = df.groupby(clusterVar).sum().T\n",
    "    df_temp = pd.DataFrame(cluster_analysis)\n",
    "    df_temp = df_temp.reset_index()\n",
    "    df_temp = df_temp[df_temp['index'].isin(mentions)]\n",
    "    top10MentionDic = {}\n",
    "    for i in df_temp.columns[1:].tolist():\n",
    "        top_10 = df_temp[['index', i]].sort_values(by=i, ascending=False).head(10)\n",
    "        top10MentionDic[i] = top_10['index'].tolist()\n",
    "\n",
    "    return top10MentionDic\n",
    "\n",
    "\n",
    "# Funktion: Ausgabe der Top 10 Themen pro Cluster\n",
    "def printTop10Mentions(top10Mentions):\n",
    "    for key, values in top10Mentions.items():\n",
    "        print(f\"Cluster {key}: \" + ', '.join(values))\n",
    "\n",
    "\n",
    "# Funktion: Alter pro Cluster \n",
    "def plotAgePerCluster(ax, df, clusterName):\n",
    "    df_temp = df.groupby([\"age\", clusterName]).size().unstack(fill_value=0)\n",
    "    df_temp.plot(kind=\"bar\", stacked=True, ax=ax)\n",
    "\n",
    "    ax.set_title(\"Altersverteilung pro Cluster\")\n",
    "    ax.set_xlabel(\"Alter\")\n",
    "    ax.set_ylabel(\"Anzahl\")\n",
    "    ax.legend(title=\"Cluster\", loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "\n",
    "# Funktion: Alter pro Cluster \n",
    "def plotGenderPerCluster(ax, df, clusterName):\n",
    "    df_temp = df.groupby([\"gender\", clusterName]).size().unstack(fill_value=0)\n",
    "    df_temp.plot(kind=\"bar\", stacked=True, ax=ax)\n",
    "\n",
    "    ax.set_title(\"Geschlechtsverteilung pro Cluster\")\n",
    "    ax.set_xlabel(\"Geschlecht\")\n",
    "    ax.set_ylabel(\"Anzahl\")\n",
    "    ax.legend(title=\"Cluster\", loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "# Funktion: Wortnennungen pro Cluster \n",
    "def plotWordMentionsperCluster(ax, df, clusterName, mentions_var):\n",
    "    df_temp = pd.melt(df, id_vars=[clusterName], value_vars=mentions_var, var_name='Mentions', value_name='Anzahl')\n",
    "    df_temp = df_temp.pivot_table(index='Mentions', columns=clusterName, values='Anzahl', fill_value=0)\n",
    "    df_temp.plot(kind='bar', stacked=True, ax=ax)\n",
    "\n",
    "    ax.set_title(\"Wortnennungen pro Cluster\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Anzahl\")\n",
    "    ax.legend(title=\"Cluster\", loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "# t-SNE\n",
    "tSNE = TSNE(n_components=2, random_state=123) \n",
    "X_tSNE = tSNE.fit_transform(df_scaled)\n",
    "\n",
    "# Funktion: t-SNE Plot\n",
    "def plotSNE(ax, df, clusterName, X_tSNE):\n",
    "    scatter = ax.scatter(X_tSNE[:, 0], X_tSNE[:, 1], c=df[clusterName], alpha=0.3)\n",
    "    titleName = \"t-SNE \" + clusterName\n",
    "    ax.set_title(titleName)\n",
    "    ax.set_xlabel(\"Dim 1\")\n",
    "    ax.set_ylabel(\"Dim 2\")\n",
    "    plt.colorbar(scatter, ax=ax)\n",
    "\n",
    "\n",
    "# Funktion: Plot Ausgabe\n",
    "def plotClusterAnalysis(df, clusterName, mentions_var):\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    gs = GridSpec(2, 3, figure=fig)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax3 = fig.add_subplot(gs[1, :])  \n",
    "    ax4 = fig.add_subplot(gs[0, 2])\n",
    "\n",
    "\n",
    "    plotAgePerCluster(ax1, df, clusterName)\n",
    "    plotGenderPerCluster(ax2, df, clusterName)\n",
    "    plotWordMentionsperCluster(ax3, df, clusterName, mentions_var)\n",
    "    plotSNE(ax4, df, clusterName, X_tSNE)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print('\\n\\033[1mDavies-Bouldin-Index\\033[0m')\n",
    "    print(df_dbIndex[df_dbIndex['clusterName'] == clusterName]['db_index'].iloc[0])\n",
    "\n",
    "    print('\\n\\033[1mTop 10 Themen\\033[0m')\n",
    "    top10 = top10Mention(df, clusterName)\n",
    "    printTop10Mentions(top10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusterAnalysis(df, \"cluster_kmeans (k=6)\", mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusterAnalysis(df, \"cluster_kmeans (k=7)\", mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" plotClusterAnalysis(df, \"cluster_hierarch\", mentions) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusterAnalysis(df, \"cluster_dbscans\", mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusterAnalysis(df, \"cluster_fuzzy (k=6)\", mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotClusterAnalysis(df, \"cluster_fuzzy (k=7)\", mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def valueCounts(df, var):\n",
    "#     print(df[var].value_counts())\n",
    "    \n",
    "# def evaluateModell(df, var, modelName):\n",
    "#     valueCounts(df, var)\n",
    "#     personenBezogendeErgebnisse(df, modelName)\n",
    "\n",
    "# def durchschnittsAlterProCluster(df, clusterVar):\n",
    "#     mean_age = df.groupby(clusterVar)['age'].mean()\n",
    "#     for cluster, age in mean_age.items():\n",
    "#         print(f\"Cluster {cluster}: Durchschnittlich {age:.2f} Jahre\")\n",
    "\n",
    "# def verteilungGeschlechtProCluster(df, clusterVar):\n",
    "#     gender = df.groupby([clusterVar, 'gender']).size().unstack(fill_value=0)\n",
    "#     for i in gender.index:\n",
    "#         print(f\"Cluster {i}: {gender.loc[i, 1]} Frauen, {gender.loc[i, 2]} Männer, {gender.loc[i, 3]} Unbekannt\")\n",
    "\n",
    "# def durchschnittsAnzahlFreundeProCluster(df, clusterVar):\n",
    "#     mean_friends = df.groupby(clusterVar)['NumberOffriends'].mean()\n",
    "#     for cluster, avg_friends in mean_friends.items():\n",
    "#         print(f\"Cluster {cluster}: Durchschnittlich {avg_friends:.2f} Freunde\")\n",
    "\n",
    "# def personenBezogendeErgebnisse(df, clusterVar):\n",
    "#     durchschnittsAlterProCluster(df, clusterVar)\n",
    "#     print('')\n",
    "#     verteilungGeschlechtProCluster(df, clusterVar)\n",
    "#     print('')\n",
    "#     durchschnittsAnzahlFreundeProCluster(df,  clusterVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluateModell(df, modelName):\n",
    "#     print('\\033[1mAnzahl Einträge pro Cluster\\033[0m')\n",
    "#     valueCounts(df,modelName,  )\n",
    "#     print('\\n\\033[1mPersonen Bezogene Ergebnisse\\033[0m')\n",
    "#     personenBezogendeErgebnisse(df, modelName)\n",
    "#     print('\\n\\033[1mTop 10 Themen\\033[0m')\n",
    "#     top10 = top10Mention(df, modelName)\n",
    "#     printTop10Mentions(top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluateModell(df,'cluster_kmeans' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_sport = ['basketball', 'football', 'soccer', 'softball', 'volleyball', 'swimming', 'cheerleading', 'baseball', 'tennis', 'sports']\n",
    "# list_emotions = ['cute', 'sex', 'sexy', 'hot', 'kissed']\n",
    "# list_music = ['dance', 'band', 'marching', 'music', 'rock']\n",
    "# list_religion:  ['god', 'church', 'jesus', 'bible']\n",
    "# list_fashion: ['hair', 'dress', 'blonde', 'mall', 'shopping', 'clothes', 'hollister', 'abercrombie']\n",
    "# list_death: ['die', 'death']\n",
    "# list_drug:'[drunk', 'drugs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
